{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data here\n",
    "df1 = pd.read_csv(\"imnemato-youtube[1080p]-1x-vpn-mac-clean-20201031a.csv\")\n",
    "df2 = pd.read_csv(\"vpn_browsing1.csv\")\n",
    "\n",
    "df3 = pd.read_csv(\"pgaddiso-youtube-1x-720p-vpn-linux-clean-20201102-1.csv\")\n",
    "df4 = pd.read_csv(\"vpn_browsing2.csv\")\n",
    "\n",
    "\n",
    "df5 = windows_video_vpn = pd.read_csv(\"stdoan-youtube[720p60]-1x-vpn-windows-clean-20201102.csv\")\n",
    "df6 = pd.read_csv(\"vpn_browsing3.csv\")\n",
    "\n",
    "# make sure that dataframes are in list\n",
    "list_of_frames = [df1, df2, df3,df4,df5,df6]\n",
    "#add vpn dataframes to next list\n",
    "video_frames = [df1,df3,df5]\n",
    "browsing_frames = [df2,df4,df6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "# helper method to sum all package lengths for each entry in a column\n",
    "def package(input1):\n",
    "    sum1 = 0\n",
    "    for x in input1:\n",
    "        if x  != \"\":\n",
    "            sum1 += int(x)\n",
    "    return sum1\n",
    "\n",
    "# adds total pacakge length to all dataframes\n",
    "def packet_length(frames):\n",
    "    for j in frames:\n",
    "        j[\"sum of sizes\"] = pd.Series(j.packet_sizes.apply(lambda x: x.split(\";\"))).apply(lambda x: package(x))\n",
    "\n",
    "#label the data\n",
    "def label():\n",
    "    for x in video_frames:\n",
    "            x[\"Label\"] = 1\n",
    "    for j in browsing_frames:\n",
    "            j[\"Label\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labes data \n",
    "label()\n",
    "\n",
    "# total packet length\n",
    "packet_length(list_of_frames)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_model_data(frames):\n",
    "    # global_varaiables for data storage\n",
    "    X_train_df =  None\n",
    "    X_test_df  = None\n",
    "    y_train_df = None\n",
    "    y_test_df = None\n",
    "\n",
    "    for f in frames:\n",
    "        #isolate features in frames\n",
    "        X = f[[\"sum of sizes\", \"1->2Bytes\",\"2->1Bytes\"]]\n",
    "        \n",
    "        #isolate label\n",
    "        y = f[[\"Label\"]]\n",
    "        \n",
    "        #split data between training and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) \n",
    "       \n",
    "        #gatther data from all dataframes\n",
    "        X_train_df = pd.concat([X_train_df, X_train])\n",
    "        X_test_df = pd.concat([X_test_df, X_test])\n",
    "        y_train_df = pd.concat([y_train_df, y_train])\n",
    "        y_test_df = pd.concat([y_test_df, y_test])\n",
    "        \n",
    "        \n",
    "        \n",
    "    return [X_train_df,X_test_df,y_train_df,y_test_df]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data = ml_model_data(list_of_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_predictions(ml_model_data):\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(ml_model_data[0], ml_model_data[2])\n",
    "    predictions = clf.predict(ml_model_data[1])\n",
    "    \n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dania\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\dania\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "predictions = making_predictions(All_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegression()\n",
    "# clf.fit(All_data[0], All_data[1])\n",
    "# predictions = clf.predict(ml_model_data[2])\n",
    "# predictions\n",
    "mse = mean_squared_error(All_data[3][\"Label\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(prediction, confidence):\n",
    "    min_value = min(prediction)\n",
    "    max_value = max(prediction)\n",
    "    \n",
    "    average_list = []\n",
    "    \n",
    "    for x in range(1000):\n",
    "        samples = np.random.choice(prediction, len(prediction))\n",
    "        average_list.append(np.mean(samples))\n",
    "    \n",
    "    size = len(average_list)\n",
    "    average = np.mean(average_list)\n",
    "    st_error = stats.sem(average_list)\n",
    "    interval = st_error * t.ppf((1 + confidence)/2,size-1)\n",
    "    low = round(average- interval)\n",
    "    up = round(average +interval)\n",
    "    return (low, up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval =confidence_interval(predictions,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prdicitons from my ML model are [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"The prdicitons from my ML model are\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean square error of my model is 0.7250932338838573\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean square error of my model is\" , mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence intervale of my model is  (1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"The confidence intervale of my model is \",interval )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
